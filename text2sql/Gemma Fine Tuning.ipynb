{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11861301,"sourceType":"datasetVersion","datasetId":7453378},{"sourceId":282742,"sourceType":"modelInstanceVersion","modelInstanceId":239467,"modelId":222398}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U transformers\n!pip install -q -U accelerate\n!pip install -q -U datasets\n!pip install -q -U peft\n!pip install -q -i https://pypi.org/simple/ bitsandbytes\n!pip install -q -U trl\n!pip install rouge-score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\n\nhf_token = \"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\"\n\nlogin(hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:12.081848Z","iopub.execute_input":"2025-05-18T20:10:12.082555Z","iopub.status.idle":"2025-05-18T20:10:12.640299Z","shell.execute_reply.started":"2025-05-18T20:10:12.082519Z","shell.execute_reply":"2025-05-18T20:10:12.633905Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:12.641681Z","iopub.execute_input":"2025-05-18T20:10:12.641952Z","iopub.status.idle":"2025-05-18T20:10:12.652079Z","shell.execute_reply.started":"2025-05-18T20:10:12.641928Z","shell.execute_reply":"2025-05-18T20:10:12.650037Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:12.982509Z","iopub.execute_input":"2025-05-18T20:10:12.983183Z","iopub.status.idle":"2025-05-18T20:10:12.987261Z","shell.execute_reply.started":"2025-05-18T20:10:12.983150Z","shell.execute_reply":"2025-05-18T20:10:12.986320Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\n\nimport transformers\nfrom transformers import (AutoModelForCausalLM,\n                          AutoTokenizer,\n                          BitsAndBytesConfig,\n                          TrainingArguments, # Note: SFTConfig from TRL is used later\n                          pipeline,\n                          logging)\n\n# Explicitly import Gemma3ForCausalLM\nfrom transformers.models.gemma3 import Gemma3ForCausalLM\n\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig, PeftModel\n\nimport bitsandbytes as bnb\n\nfrom sklearn.metrics import (accuracy_score,\n                             classification_report,\n                             confusion_matrix)\n\nfrom sklearn.model_selection import train_test_split\n\n# Check transformers version\nprint(f\"transformers=={transformers.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:13.504508Z","iopub.execute_input":"2025-05-18T20:10:13.505244Z","iopub.status.idle":"2025-05-18T20:10:22.444246Z","shell.execute_reply.started":"2025-05-18T20:10:13.505217Z","shell.execute_reply":"2025-05-18T20:10:22.443463Z"}},"outputs":[{"name":"stderr","text":"2025-05-18 20:10:18.443262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747599018.466553     482 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747599018.473466     482 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"transformers==4.51.3\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def define_device():\n    \"\"\"Determine and return the optimal PyTorch device based on availability.\"\"\"\n\n    print(f\"PyTorch version: {torch.__version__}\", end=\" -- \")\n\n    # Check if MPS (Metal Performance Shaders) is available for macOS\n    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n        print(\"using MPS device on macOS\")\n        return torch.device(\"mps\")\n\n    # Check for CUDA availability\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"using {device}\")\n    return device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:22.445545Z","iopub.execute_input":"2025-05-18T20:10:22.446391Z","iopub.status.idle":"2025-05-18T20:10:22.451029Z","shell.execute_reply.started":"2025-05-18T20:10:22.446369Z","shell.execute_reply":"2025-05-18T20:10:22.450192Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Determine optimal computation dtype based on GPU capability\n# Use bfloat16 if Compute Capability >= 8.0, otherwise float16\ncompute_dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\nprint(f\"Using compute dtype {compute_dtype}\")\n\n# Select the best available device (CPU, CUDA, or MPS)\ndevice = define_device()\nprint(f\"Operating on {device}\")\n\n# Path to the pre-trained model (adjust if necessary)\nGEMMA_PATH = \"/kaggle/input/gemma-3/transformers/gemma-3-1b-it/1\"\n\n# Load the model with optimized settings\nmodel = Gemma3ForCausalLM.from_pretrained(\n    GEMMA_PATH,\n    torch_dtype=compute_dtype,\n    attn_implementation=\"eager\", # Specify attention implementation\n    low_cpu_mem_usage=True,      # Reduces CPU RAM usage during loading\n    device_map=device            # Automatically map model layers to the device\n)\n\n# Define maximum sequence length for the tokenizer\nmax_seq_length = 8192 # Gemma 3 supports long contexts\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    GEMMA_PATH,\n    max_seq_length=max_seq_length,\n    device_map=device # Map tokenizer operations if relevant (less common)\n)\n\n# Store the EOS token for later use in prompts\nEOS_TOKEN = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:22.451726Z","iopub.execute_input":"2025-05-18T20:10:22.451916Z","iopub.status.idle":"2025-05-18T20:10:26.160180Z","shell.execute_reply.started":"2025-05-18T20:10:22.451900Z","shell.execute_reply":"2025-05-18T20:10:26.159561Z"}},"outputs":[{"name":"stdout","text":"Using compute dtype torch.float16\nPyTorch version: 2.6.0+cu124 -- using cuda\nOperating on cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Check if all model parameters are on the CUDA device\nis_on_gpu = all(param.device.type == 'cuda' for param in model.parameters())\nprint(\"Model is on GPU:\", is_on_gpu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:26.161759Z","iopub.execute_input":"2025-05-18T20:10:26.161982Z","iopub.status.idle":"2025-05-18T20:10:26.167443Z","shell.execute_reply.started":"2025-05-18T20:10:26.161964Z","shell.execute_reply":"2025-05-18T20:10:26.166725Z"}},"outputs":[{"name":"stdout","text":"Model is on GPU: True\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def apply_qa_template_train(row):\n    return f\"\"\"<|system|>\nТы помощник, который помогает переводить вопросы на русском языке в SQL-запросы к базе данных.</s>\n<|user|>\nКонтекст таблицы:\n{row['context']}\n\nВопрос:\n{row['translated_question']}</s>\n<|assistant|>\n{row['answer']}\"\"\"\n\ndef transform_train_data(data):\n  return apply_qa_template_train(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:26.168113Z","iopub.execute_input":"2025-05-18T20:10:26.168349Z","iopub.status.idle":"2025-05-18T20:10:26.181064Z","shell.execute_reply.started":"2025-05-18T20:10:26.168328Z","shell.execute_reply":"2025-05-18T20:10:26.180331Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def apply_qa_template_eval(row):\n    return f\"\"\"<|system|>\nТы — специалист по базам данных. На основе контекста и вопроса на русском языке сгенерируй только SQL-запрос. Никаких пояснений, только SQL.</s>\n<|user|>\nКонтекст таблицы:\n{row['context']}\n\nЗапрос:\n{row['translated_question']}</s>\n<|assistant|>\n\"\"\"\n\ndef transform_eval_data(data):\n  return apply_qa_template_eval(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:26.181792Z","iopub.execute_input":"2025-05-18T20:10:26.182028Z","iopub.status.idle":"2025-05-18T20:10:26.195585Z","shell.execute_reply.started":"2025-05-18T20:10:26.182005Z","shell.execute_reply":"2025-05-18T20:10:26.194904Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/dataset/data_translated.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:26.196346Z","iopub.execute_input":"2025-05-18T20:10:26.196591Z","iopub.status.idle":"2025-05-18T20:10:26.685770Z","shell.execute_reply.started":"2025-05-18T20:10:26.196571Z","shell.execute_reply":"2025-05-18T20:10:26.685145Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:26.686506Z","iopub.execute_input":"2025-05-18T20:10:26.686751Z","iopub.status.idle":"2025-05-18T20:10:26.699142Z","shell.execute_reply.started":"2025-05-18T20:10:26.686730Z","shell.execute_reply":"2025-05-18T20:10:26.698297Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                             context  \\\n0                    CREATE TABLE head (age INTEGER)   \n1  CREATE TABLE head (name VARCHAR, born_state VA...   \n2  CREATE TABLE department (creation VARCHAR, nam...   \n3  CREATE TABLE department (budget_in_billions IN...   \n4  CREATE TABLE department (num_employees INTEGER...   \n\n                                            question  \\\n0  How many heads of the departments are older th...   \n1  List the name, born state and age of the heads...   \n2  List the creation year, name and budget of eac...   \n3  What are the maximum and minimum budget of the...   \n4  What is the average number of employees of the...   \n\n                                              answer  \\\n0           SELECT COUNT(*) FROM head WHERE age > 56   \n1  SELECT name, born_state, age FROM head ORDER B...   \n2  SELECT creation, name, budget_in_billions FROM...   \n3  SELECT MAX(budget_in_billions), MIN(budget_in_...   \n4  SELECT AVG(num_employees) FROM department WHER...   \n\n                                 translated_question  \n0  Сколько руководителей департаментов старше 56 ...  \n1  Укажите фамилию, имя, отчество и возраст руков...  \n2  Укажите год создания, название и бюджет каждог...  \n3  Каковы максимальный и минимальный бюджет депар...  \n4  Каково среднее число сотрудников департаментов...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>translated_question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CREATE TABLE head (age INTEGER)</td>\n      <td>How many heads of the departments are older th...</td>\n      <td>SELECT COUNT(*) FROM head WHERE age &gt; 56</td>\n      <td>Сколько руководителей департаментов старше 56 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CREATE TABLE head (name VARCHAR, born_state VA...</td>\n      <td>List the name, born state and age of the heads...</td>\n      <td>SELECT name, born_state, age FROM head ORDER B...</td>\n      <td>Укажите фамилию, имя, отчество и возраст руков...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CREATE TABLE department (creation VARCHAR, nam...</td>\n      <td>List the creation year, name and budget of eac...</td>\n      <td>SELECT creation, name, budget_in_billions FROM...</td>\n      <td>Укажите год создания, название и бюджет каждог...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CREATE TABLE department (budget_in_billions IN...</td>\n      <td>What are the maximum and minimum budget of the...</td>\n      <td>SELECT MAX(budget_in_billions), MIN(budget_in_...</td>\n      <td>Каковы максимальный и минимальный бюджет депар...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CREATE TABLE department (num_employees INTEGER...</td>\n      <td>What is the average number of employees of the...</td>\n      <td>SELECT AVG(num_employees) FROM department WHER...</td>\n      <td>Каково среднее число сотрудников департаментов...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"train_df, eval_df = train_test_split(data, test_size=0.1, random_state=77)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:26.700196Z","iopub.execute_input":"2025-05-18T20:10:26.700434Z","iopub.status.idle":"2025-05-18T20:10:26.723189Z","shell.execute_reply.started":"2025-05-18T20:10:26.700417Z","shell.execute_reply":"2025-05-18T20:10:26.722398Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_df[\"text\"] = train_df.apply(transform_train_data, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:26.725336Z","iopub.execute_input":"2025-05-18T20:10:26.725542Z","iopub.status.idle":"2025-05-18T20:10:27.306899Z","shell.execute_reply.started":"2025-05-18T20:10:26.725527Z","shell.execute_reply":"2025-05-18T20:10:27.306117Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"eval_df[\"text\"] = eval_df.apply(transform_eval_data, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:27.307775Z","iopub.execute_input":"2025-05-18T20:10:27.308058Z","iopub.status.idle":"2025-05-18T20:10:27.361252Z","shell.execute_reply.started":"2025-05-18T20:10:27.308034Z","shell.execute_reply":"2025-05-18T20:10:27.360718Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df[[\"text\"]]).select(range(10000))\neval_dataset = Dataset.from_pandas(eval_df[[\"text\"]]).select(range(1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:27.361926Z","iopub.execute_input":"2025-05-18T20:10:27.362132Z","iopub.status.idle":"2025-05-18T20:10:27.762951Z","shell.execute_reply.started":"2025-05-18T20:10:27.362116Z","shell.execute_reply":"2025-05-18T20:10:27.762413Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(eval_df.iloc[0][\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:27.763645Z","iopub.execute_input":"2025-05-18T20:10:27.763849Z","iopub.status.idle":"2025-05-18T20:10:27.768458Z","shell.execute_reply.started":"2025-05-18T20:10:27.763833Z","shell.execute_reply":"2025-05-18T20:10:27.767657Z"}},"outputs":[{"name":"stdout","text":"<|system|>\nТы — специалист по базам данных. На основе контекста и вопроса на русском языке сгенерируй только SQL-запрос. Никаких пояснений, только SQL.</s>\n<|user|>\nКонтекст таблицы:\nCREATE TABLE table_name_5 (date VARCHAR, opponents VARCHAR)\n\nЗапрос:\nТурнир с соперницей Келли Де Бир Евой Пера был сыгран в какой день?\n</s>\n<|assistant|>\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(train_df.iloc[0][\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:27.769134Z","iopub.execute_input":"2025-05-18T20:10:27.769436Z","iopub.status.idle":"2025-05-18T20:10:27.782301Z","shell.execute_reply.started":"2025-05-18T20:10:27.769419Z","shell.execute_reply":"2025-05-18T20:10:27.781744Z"}},"outputs":[{"name":"stdout","text":"<|system|>\nТы помощник, который помогает переводить вопросы на русском языке в SQL-запросы к базе данных.</s>\n<|user|>\nКонтекст таблицы:\nCREATE TABLE table_name_97 (crowd INTEGER, home_team VARCHAR)\n\nВопрос:\nКакая самая маленькая толпа была на домашнем матче \"Эссендона\"?\n</s>\n<|assistant|>\nSELECT MIN(crowd) FROM table_name_97 WHERE home_team = \"essendon\"\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def predict_sql(eval_df, model, tokenizer, device=\"cuda\", max_new_tokens=128, temperature=0.0):\n    \"\"\"Генерация SQL-запросов по текстовому промпту в формате ChatML.\"\"\"\n    predicted_sql = []\n\n    model.eval()\n\n    for i in tqdm(range(len(eval_df)), desc=\"Генерация SQL\"):\n        prompt = eval_df[i][\"text\"]  # поле без gold answer\n\n        # Токенизация\n        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n\n        # Генерация\n        with torch.no_grad():\n            outputs = model.generate(\n                **input_ids,\n                max_new_tokens=max_new_tokens,\n                temperature=temperature,\n                pad_token_id=tokenizer.eos_token_id,\n                eos_token_id=tokenizer.eos_token_id,\n                do_sample=False\n            )\n\n        # Декодирование всего текста\n        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        # Извлекаем только SQL часть (после <|assistant|>)\n        if \"<|assistant|>\" in decoded:\n            predicted = decoded.split(\"<|assistant|>\")[-1].strip()\n        else:\n            predicted = decoded.strip()\n\n        predicted_sql.append(predicted)\n\n    return predicted_sql","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:27.783162Z","iopub.execute_input":"2025-05-18T20:10:27.783422Z","iopub.status.idle":"2025-05-18T20:10:27.795833Z","shell.execute_reply.started":"2025-05-18T20:10:27.783401Z","shell.execute_reply":"2025-05-18T20:10:27.795106Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# eval_predicted = predict_sql(eval_df=eval_dataset, model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:27.796576Z","iopub.execute_input":"2025-05-18T20:10:27.796740Z","iopub.status.idle":"2025-05-18T20:10:27.811067Z","shell.execute_reply.started":"2025-05-18T20:10:27.796724Z","shell.execute_reply":"2025-05-18T20:10:27.810367Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"print(eval_df.iloc[3][\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:27.829683Z","iopub.execute_input":"2025-05-18T20:10:27.830426Z","iopub.status.idle":"2025-05-18T20:10:27.834662Z","shell.execute_reply.started":"2025-05-18T20:10:27.830406Z","shell.execute_reply":"2025-05-18T20:10:27.833994Z"}},"outputs":[{"name":"stdout","text":"<|system|>\nТы — специалист по базам данных. На основе контекста и вопроса на русском языке сгенерируй только SQL-запрос. Никаких пояснений, только SQL.</s>\n<|user|>\nКонтекст таблицы:\nCREATE TABLE table_24172157_3 (date_of_vacancy VARCHAR, table VARCHAR, team VARCHAR)\n\nЗапрос:\nКакова дата освобождения места для команды \"Ливерпуль\", таблица которой называется предсезонной?\n</s>\n<|assistant|>\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(eval_df.iloc[3][\"answer\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_predicted[3]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_predicted","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef clean_sql(text):\n    \"\"\"\n    Удаляет обёртки ```sql ... ``` и обрезает по первой строке, если нужно.\n    \"\"\"\n    if not isinstance(text, str):\n        return \"\"\n\n    # Убираем блоки ```sql и ```\n    cleaned = re.sub(r\"```sql\\s*\", \"\", text, flags=re.IGNORECASE)\n    cleaned = re.sub(r\"```\", \"\", cleaned)\n    return cleaned.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:30.792469Z","iopub.execute_input":"2025-05-18T20:10:30.793045Z","iopub.status.idle":"2025-05-18T20:10:30.797463Z","shell.execute_reply.started":"2025-05-18T20:10:30.793023Z","shell.execute_reply":"2025-05-18T20:10:30.796474Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"clean_predicts = list(map(clean_sql, eval_predicted))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answers = eval_df.head(50)[\"answer\"].to_list()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nimport numpy as np\n\ndef compute_rouge_scores(predictions, references, use_stemmer=True):\n    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=use_stemmer)\n\n    scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n\n    for pred, ref in zip(predictions, references):\n        result = scorer.score(ref, pred)\n        for key in scores:\n            scores[key].append(result[key].fmeasure)\n\n    return {\n        \"ROUGE-1\": round(np.mean(scores[\"rouge1\"]), 4),\n        \"ROUGE-2\": round(np.mean(scores[\"rouge2\"]), 4),\n        \"ROUGE-L\": round(np.mean(scores[\"rougeL\"]), 4),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:33.830658Z","iopub.execute_input":"2025-05-18T20:10:33.831388Z","iopub.status.idle":"2025-05-18T20:10:34.005600Z","shell.execute_reply.started":"2025-05-18T20:10:33.831365Z","shell.execute_reply":"2025-05-18T20:10:34.005044Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"compute_rouge_scores(clean_predicts, answers)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\nfrom peft import LoraConfig\n\n# LoRA Configuration\npeft_config = LoraConfig(\n    lora_alpha=16,                           # Scaling factor for LoRA\n    lora_dropout=0.05,                       # Add slight dropout for regularization\n    r=64,                                    # Rank of the LoRA update matrices\n    bias=\"none\",                             # No bias reparameterization\n    task_type=\"CAUSAL_LM\",                   # Task type: Causal Language Modeling\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n    ],  # Target modules for LoRA\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:35.949391Z","iopub.execute_input":"2025-05-18T20:10:35.949928Z","iopub.status.idle":"2025-05-18T20:10:35.954317Z","shell.execute_reply.started":"2025-05-18T20:10:35.949905Z","shell.execute_reply":"2025-05-18T20:10:35.953456Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:37.206271Z","iopub.execute_input":"2025-05-18T20:10:37.206953Z","iopub.status.idle":"2025-05-18T20:10:37.210651Z","shell.execute_reply.started":"2025-05-18T20:10:37.206932Z","shell.execute_reply":"2025-05-18T20:10:37.209754Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"output\",\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=4,\n    optim=\"adamw_torch\",\n    num_train_epochs=2,\n    logging_steps=0.2,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    group_by_length=True,\n    report_to=\"none\",\n    remove_unused_columns=False, \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:38.935249Z","iopub.execute_input":"2025-05-18T20:10:38.935530Z","iopub.status.idle":"2025-05-18T20:10:38.967852Z","shell.execute_reply.started":"2025-05-18T20:10:38.935508Z","shell.execute_reply":"2025-05-18T20:10:38.967118Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def tokenize(example):\n    out = tokenizer(\n        example[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=1024,\n    )\n    out[\"labels\"] = out[\"input_ids\"].copy()\n    return out\n\ntokenized_train = train_dataset.map(tokenize, remove_columns=[\"text\"])\ntokenized_eval = eval_dataset.map(tokenize, remove_columns=[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:40.593692Z","iopub.execute_input":"2025-05-18T20:10:40.594157Z","iopub.status.idle":"2025-05-18T20:10:53.541798Z","shell.execute_reply.started":"2025-05-18T20:10:40.594133Z","shell.execute_reply":"2025-05-18T20:10:53.541000Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afa3eca45e804b97a590c55494068289"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6959267ddc3d4ccca362f63712b3c7f7"}},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_eval,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T20:10:53.543102Z","iopub.execute_input":"2025-05-18T20:10:53.543385Z","iopub.status.idle":"2025-05-18T20:10:54.129807Z","shell.execute_reply.started":"2025-05-18T20:10:53.543358Z","shell.execute_reply":"2025-05-18T20:10:54.129044Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:23:05.786222Z","iopub.execute_input":"2025-05-19T04:23:05.786629Z","iopub.status.idle":"2025-05-19T04:23:05.794367Z","shell.execute_reply.started":"2025-05-19T04:23:05.786601Z","shell.execute_reply":"2025-05-19T04:23:05.793471Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4032920361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"],"ename":"NameError","evalue":"name 'trainer' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"model.save_pretrained(\"gemma3:1b-text2sql-lora\")\ntokenizer.save_pretrained(\"gemma3:1b-text2sql-lora\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T22:27:26.771570Z","iopub.status.idle":"2025-05-18T22:27:26.771945Z","shell.execute_reply.started":"2025-05-18T22:27:26.771760Z","shell.execute_reply":"2025-05-18T22:27:26.771777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\n# Название репозитория\nrepo_name = \"your-username/gemma3:1b-text2sql-lora\"\n\n# Создаём репозиторий (если ещё нет)\napi = HfApi()\napi.create_repo(repo_name, repo_type=\"model\", private=False)  # или private=True\n\n# Загружаем\nfrom huggingface_hub import upload_folder\n\nupload_folder(\n    repo_id=repo_name,\n    folder_path=\"gemma3-text2sql-lora\",\n    repo_type=\"model\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.push_to_hub(\"Arsench1k/gemma3:1b-text2sql-lora\")\n# tokenizer.push_to_hub(\"Arsench1k/gemma3:1b-text2sql-lora\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}